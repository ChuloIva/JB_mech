{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jailbreak Mechanism Analysis: Assistant Axis + GLP\n",
    "\n",
    "This notebook implements the full research pipeline for analyzing jailbreak mechanisms\n",
    "in Llama 3.1 8B using the Assistant Axis and Generative Latent Prior (GLP).\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**Does jailbreaking work by:**\n",
    "1. Pushing away from the Assistant Axis (suppressing the \"helpful assistant\" identity)?\n",
    "2. Activating specific harmful personas (\"criminal\", \"hacker\", etc.)?\n",
    "3. Both (combination)?\n",
    "4. Neither (orthogonal mechanism)?\n",
    "\n",
    "## Sections\n",
    "1. Setup & Installation\n",
    "2. Compute/Load Assistant Axis\n",
    "3. Data Collection\n",
    "4. Activation Extraction\n",
    "5. Projection Analysis\n",
    "6. GLP Safety Space (H, J, R)\n",
    "7. Visualization\n",
    "8. Statistical Analysis\n",
    "9. Steering Experiments\n",
    "10. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive for persistent storage\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Clone repositories\n",
    "    !git clone https://github.com/safety-research/assistant-axis.git /content/assistant-axis\n",
    "    !git clone https://github.com/YOUR_REPO/generative_latent_prior.git /content/generative_latent_prior\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install -q torch transformers accelerate vllm\n",
    "    !pip install -q diffusers einops omegaconf safetensors\n",
    "    !pip install -q git+https://github.com/davidbau/baukit\n",
    "    !pip install -q nanogcg datasets scikit-learn scipy pandas\n",
    "    !pip install -q matplotlib plotly seaborn huggingface_hub tqdm\n",
    "    \n",
    "    # Set paths\n",
    "    PROJECT_ROOT = '/content'\n",
    "    THIRD_PARTY_DIR = '/content'\n",
    "else:\n",
    "    # Local environment\n",
    "    PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "    THIRD_PARTY_DIR = os.path.join(PROJECT_ROOT, 'third_party')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Third party: {THIRD_PARTY_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add paths and import modules\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(PROJECT_ROOT, 'src'))\n",
    "sys.path.insert(0, os.path.join(THIRD_PARTY_DIR, 'assistant-axis'))\n",
    "sys.path.insert(0, os.path.join(THIRD_PARTY_DIR, 'generative_latent_prior'))\n",
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "TARGET_LAYER = 16\n",
    "TOTAL_LAYERS = 32\n",
    "GLP_MODEL = \"generative-latent-prior/glp-llama8b-d6\"\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(PROJECT_ROOT) / \"outputs\" / \"llama-3.1-8b\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AXIS_PATH = OUTPUT_DIR / \"axis.pt\"\n",
    "JAILBREAKS_PATH = OUTPUT_DIR / \"jailbreaks\" / \"jailbreaks.pt\"\n",
    "ACTIVATIONS_PATH = OUTPUT_DIR / \"activations\"\n",
    "ACTIVATIONS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Compute/Load Assistant Axis\n",
    "\n",
    "The Assistant Axis captures the direction from \"role-playing character\" to \"default assistant\".\n",
    "Computing it requires the full 5-step pipeline (expensive), so we check for a cached version first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if axis exists\n",
    "if AXIS_PATH.exists():\n",
    "    print(f\"Loading cached axis from {AXIS_PATH}\")\n",
    "    axis = torch.load(AXIS_PATH)\n",
    "    print(f\"Axis shape: {axis.shape}\")\n",
    "else:\n",
    "    print(\"No cached axis found. You need to compute it using the pipeline.\")\n",
    "    print(\"\\nTo compute the axis, run these commands:\")\n",
    "    print(f\"\"\"  \n",
    "    cd {THIRD_PARTY_DIR}/assistant-axis\n",
    "    \n",
    "    # Step 1: Generate responses for 275 roles\n",
    "    python pipeline/1_generate.py --model {MODEL_NAME} --output_dir {OUTPUT_DIR}/responses\n",
    "    \n",
    "    # Step 2: Extract activations  \n",
    "    python pipeline/2_activations.py --model {MODEL_NAME} --responses_dir {OUTPUT_DIR}/responses --output_dir {OUTPUT_DIR}/activations\n",
    "    \n",
    "    # Step 3: Judge responses (requires OPENAI_API_KEY)\n",
    "    python pipeline/3_judge.py --responses_dir {OUTPUT_DIR}/responses --output_dir {OUTPUT_DIR}/judgments\n",
    "    \n",
    "    # Step 4: Compute per-role vectors\n",
    "    python pipeline/4_vectors.py --activations_dir {OUTPUT_DIR}/activations --judgments_dir {OUTPUT_DIR}/judgments --output_dir {OUTPUT_DIR}/vectors\n",
    "    \n",
    "    # Step 5: Compute assistant axis\n",
    "    python pipeline/5_axis.py --vectors_dir {OUTPUT_DIR}/vectors --output {AXIS_PATH}\n",
    "    \"\"\")\n",
    "    axis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Data Collection\n",
    "\n",
    "Load datasets for jailbreak analysis:\n",
    "- JailbreakBench: Curated harmful behaviors\n",
    "- Proven jailbreaks: Known successful attacks\n",
    "- Alpaca: Benign prompts for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load JailbreakBench behaviors\n",
    "print(\"Loading JailbreakBench...\")\n",
    "jbb = load_dataset(\"JailbreakBench/JBB-Behaviors\", \"behaviors\")\n",
    "behaviors = [{\"id\": i, \"goal\": b[\"Goal\"], \"target\": b[\"Target\"]} for i, b in enumerate(jbb[\"train\"])]\n",
    "print(f\"Loaded {len(behaviors)} harmful behaviors\")\n",
    "\n",
    "# Load Alpaca for benign baseline\n",
    "print(\"\\nLoading Alpaca...\")\n",
    "alpaca = load_dataset(\"tatsu-lab/alpaca\")\n",
    "benign_prompts = [item[\"instruction\"] for item in alpaca[\"train\"][:100] if item[\"instruction\"].strip()]\n",
    "print(f\"Loaded {len(benign_prompts)} benign prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample behaviors for analysis (use subset for faster iteration)\n",
    "N_BEHAVIORS = 50  # Adjust based on compute budget\n",
    "\n",
    "sample_behaviors = behaviors[:N_BEHAVIORS]\n",
    "sample_benign = benign_prompts[:N_BEHAVIORS]\n",
    "\n",
    "print(f\"Using {len(sample_behaviors)} harmful behaviors\")\n",
    "print(f\"Using {len(sample_benign)} benign prompts\")\n",
    "\n",
    "# Create prompt lists\n",
    "clean_harmful_prompts = [b[\"goal\"] for b in sample_behaviors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load pre-generated jailbreaks\n",
    "if JAILBREAKS_PATH.exists():\n",
    "    print(f\"Loading jailbreaks from {JAILBREAKS_PATH}\")\n",
    "    jailbreaks = torch.load(JAILBREAKS_PATH)\n",
    "    print(f\"Loaded {len(jailbreaks)} jailbreaks\")\n",
    "else:\n",
    "    print(\"No cached jailbreaks found.\")\n",
    "    print(\"To generate jailbreaks with nanoGCG, run the cell below.\")\n",
    "    jailbreaks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Generate jailbreaks with nanoGCG (expensive - ~30 min per behavior)\n",
    "# Only run if needed\n",
    "\n",
    "GENERATE_JAILBREAKS = False  # Set to True to generate\n",
    "\n",
    "if GENERATE_JAILBREAKS and jailbreaks is None:\n",
    "    import nanogcg\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    \n",
    "    print(\"Loading model for GCG...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    config = nanogcg.GCGConfig(num_steps=500, seed=42)\n",
    "    \n",
    "    jailbreaks = []\n",
    "    for behavior in tqdm(sample_behaviors[:10]):  # Start with just 10\n",
    "        result = nanogcg.run(model, tokenizer, behavior[\"goal\"], behavior[\"target\"], config)\n",
    "        jailbreaks.append({\n",
    "            \"goal\": behavior[\"goal\"],\n",
    "            \"target\": behavior[\"target\"],\n",
    "            \"suffix\": result.best_string,\n",
    "            \"loss\": float(result.best_loss),\n",
    "            \"jailbreak_prompt\": f\"{behavior['goal']} {result.best_string}\"\n",
    "        })\n",
    "    \n",
    "    # Save\n",
    "    JAILBREAKS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(jailbreaks, JAILBREAKS_PATH)\n",
    "    print(f\"Saved {len(jailbreaks)} jailbreaks to {JAILBREAKS_PATH}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Activation Extraction\n",
    "\n",
    "Extract activations for all prompt categories using the Assistant Axis wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for activation extraction\n",
    "from assistant_axis.internals import ProbingModel, ConversationEncoder, ActivationExtractor\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "pm = ProbingModel(MODEL_NAME)\n",
    "encoder = ConversationEncoder(pm.tokenizer, MODEL_NAME)\n",
    "extractor = ActivationExtractor(pm, encoder)\n",
    "\n",
    "print(f\"Model loaded. Hidden size: {pm.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activations for each category\n",
    "activations = {}\n",
    "\n",
    "# Clean harmful prompts\n",
    "print(\"\\nExtracting activations for clean harmful prompts...\")\n",
    "activations[\"clean_harmful\"] = extractor.for_prompts(clean_harmful_prompts, layer=[TARGET_LAYER])\n",
    "print(f\"  Shape: {activations['clean_harmful'].shape}\")\n",
    "\n",
    "# Benign prompts\n",
    "print(\"\\nExtracting activations for benign prompts...\")\n",
    "activations[\"benign\"] = extractor.for_prompts(sample_benign, layer=[TARGET_LAYER])\n",
    "print(f\"  Shape: {activations['benign'].shape}\")\n",
    "\n",
    "# Jailbreak prompts (if available)\n",
    "if jailbreaks:\n",
    "    print(\"\\nExtracting activations for jailbreak prompts...\")\n",
    "    jailbreak_prompts = [jb[\"jailbreak_prompt\"] for jb in jailbreaks]\n",
    "    activations[\"jailbreak\"] = extractor.for_prompts(jailbreak_prompts, layer=[TARGET_LAYER])\n",
    "    print(f\"  Shape: {activations['jailbreak'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save activations\n",
    "torch.save(activations, ACTIVATIONS_PATH / \"all_activations.pt\")\n",
    "print(f\"Saved activations to {ACTIVATIONS_PATH / 'all_activations.pt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Projection Analysis\n",
    "\n",
    "Project activations onto the Assistant Axis and analyze differences between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant_axis import project, project_batch\n",
    "\n",
    "if axis is not None:\n",
    "    projections = {}\n",
    "    \n",
    "    for category, acts in activations.items():\n",
    "        # Reshape if needed: (batch,) -> project each\n",
    "        if acts.ndim == 2:\n",
    "            projs = [project(acts[i:i+1, :], axis, layer=TARGET_LAYER) for i in range(len(acts))]\n",
    "            projections[category] = torch.tensor(projs)\n",
    "        else:\n",
    "            projections[category] = project_batch(acts, axis, layer=TARGET_LAYER)\n",
    "        \n",
    "        print(f\"{category}: mean={projections[category].mean():.3f}, std={projections[category].std():.3f}\")\n",
    "else:\n",
    "    print(\"No axis loaded. Cannot compute projections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute jailbreak direction\n",
    "if axis is not None and \"jailbreak\" in activations:\n",
    "    jb_mean = activations[\"jailbreak\"][:, 0, :].mean(dim=0)\n",
    "    clean_mean = activations[\"clean_harmful\"][:, 0, :].mean(dim=0)\n",
    "    \n",
    "    jailbreak_direction = jb_mean - clean_mean\n",
    "    print(f\"Jailbreak direction norm: {jailbreak_direction.norm():.3f}\")\n",
    "    \n",
    "    # Project jailbreak direction onto axis\n",
    "    ax = axis[TARGET_LAYER].float()\n",
    "    ax_norm = ax / ax.norm()\n",
    "    jb_dir = jailbreak_direction.float()\n",
    "    \n",
    "    axis_projection = (jb_dir @ ax_norm).item()\n",
    "    variance_explained = (axis_projection ** 2) / (jb_dir ** 2).sum().item()\n",
    "    \n",
    "    print(f\"\\nJailbreak direction analysis:\")\n",
    "    print(f\"  Projection onto axis: {axis_projection:.3f}\")\n",
    "    print(f\"  Variance explained by axis: {variance_explained:.1%}\")\n",
    "    \n",
    "    if axis_projection < 0:\n",
    "        print(\"  -> Jailbreaks push AWAY from the Assistant direction\")\n",
    "    else:\n",
    "        print(\"  -> Jailbreaks push TOWARD the Assistant direction (unexpected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: GLP Safety Space (H, J, R)\n",
    "\n",
    "Use GLP to extract meta-neurons and train probes for:\n",
    "- H: Harm detection (harmful vs benign)\n",
    "- J: Jailbreak success (successful vs failed)\n",
    "- R: Refusal (model refuses vs complies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLP model\n",
    "from glp.denoiser import load_glp\n",
    "from glp.script_probe import get_meta_neurons_locations, get_meta_neurons_layer_time\n",
    "\n",
    "print(f\"Loading GLP model: {GLP_MODEL}\")\n",
    "glp = load_glp(GLP_MODEL, device=\"cuda:0\", checkpoint=\"final\")\n",
    "glp_layers = get_meta_neurons_locations(glp)\n",
    "print(f\"GLP loaded with {len(glp_layers)} meta-neuron layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract meta-neurons for all activations\n",
    "u = torch.tensor([0.9])[:, None]  # Diffusion timestep\n",
    "\n",
    "meta_neurons = {}\n",
    "for category, acts in activations.items():\n",
    "    print(f\"\\nExtracting meta-neurons for {category}...\")\n",
    "    # Reshape: (batch, 1, hidden) -> (batch, hidden)\n",
    "    X = acts[:, 0, :].float() if acts.ndim == 3 else acts.float()\n",
    "    \n",
    "    meta, (layer_size, u_size) = get_meta_neurons_layer_time(\n",
    "        glp, \"cuda:0\", X, u, glp_layers, seed=42, batch_size=64\n",
    "    )\n",
    "    meta_neurons[category] = meta\n",
    "    print(f\"  Meta-neuron shape: {meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train H probe (Harm detection)\n",
    "from glp.script_probe import prefilter_and_reshape_to_oned, run_sklearn_logreg_batched\n",
    "\n",
    "print(\"Training H probe (Harmful vs Benign)...\")\n",
    "\n",
    "# Combine meta-neurons\n",
    "X_meta = torch.cat([meta_neurons[\"clean_harmful\"], meta_neurons[\"benign\"]], dim=1)\n",
    "y = torch.cat([torch.ones(meta_neurons[\"clean_harmful\"].shape[1]), \n",
    "               torch.zeros(meta_neurons[\"benign\"].shape[1])])\n",
    "\n",
    "# Split\n",
    "n = X_meta.shape[1]\n",
    "perm = torch.randperm(n)\n",
    "split = int(n * 0.8)\n",
    "train_idx, test_idx = perm[:split], perm[split:]\n",
    "\n",
    "# Prefilter and probe\n",
    "X_train_1d, X_test_1d, top_indices = prefilter_and_reshape_to_oned(\n",
    "    X_meta[:, train_idx, :], X_meta[:, test_idx, :], y[train_idx], \"cuda:0\", topk=512\n",
    ")\n",
    "val_aucs, test_aucs = run_sklearn_logreg_batched(X_train_1d, y[train_idx], X_test_1d, y[test_idx])\n",
    "\n",
    "best_h_idx = top_indices[np.argmax(val_aucs)]\n",
    "print(f\"Best H neuron: {best_h_idx}, AUC: {test_aucs[np.argmax(val_aucs)]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly train J and R probes if we have the data\n",
    "# For J: need successful vs failed jailbreaks\n",
    "# For R: need refusal vs compliance responses\n",
    "\n",
    "# This requires running generation and classifying responses\n",
    "# Placeholder for full implementation\n",
    "\n",
    "print(\"\\nNote: Full H, J, R training requires:\")\n",
    "print(\"  - J probe: successful vs failed jailbreak responses\")\n",
    "print(\"  - R probe: refusal vs compliance responses\")\n",
    "print(\"\\nRun generation and classification to get this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot axis projection distributions\n",
    "if axis is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    for category, projs in projections.items():\n",
    "        data.append(projs.numpy())\n",
    "        labels.append(category)\n",
    "    \n",
    "    parts = ax.violinplot(data, showmeans=True, showmedians=True)\n",
    "    ax.set_xticks(range(1, len(labels) + 1))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Projection on Assistant Axis')\n",
    "    ax.set_title('Jailbreak vs Clean: Assistant Axis Projections')\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'axis_projections.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Collect all activations\n",
    "all_acts = []\n",
    "all_labels = []\n",
    "for category, acts in activations.items():\n",
    "    a = acts[:, 0, :].numpy() if acts.ndim == 3 else acts.numpy()\n",
    "    all_acts.append(a)\n",
    "    all_labels.extend([category] * len(a))\n",
    "\n",
    "all_acts = np.vstack(all_acts)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "embedded = pca.fit_transform(all_acts)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "categories = list(set(all_labels))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(categories)))\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "    mask = np.array(all_labels) == cat\n",
    "    ax.scatter(embedded[mask, 0], embedded[mask, 1], c=[colors[i]], label=cat, alpha=0.6)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "ax.set_title('Activation Space (PCA)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'pca_activations.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "if axis is not None and len(projections) >= 2:\n",
    "    print(\"Statistical Tests for Hypothesis 1: Jailbreaks = Anti-Assistant\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if \"jailbreak\" in projections and \"clean_harmful\" in projections:\n",
    "        jb_projs = projections[\"jailbreak\"].numpy()\n",
    "        clean_projs = projections[\"clean_harmful\"].numpy()\n",
    "        \n",
    "        # Mann-Whitney U test\n",
    "        stat, p = stats.mannwhitneyu(jb_projs, clean_projs, alternative='less')\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt(((len(jb_projs)-1)*jb_projs.std()**2 + (len(clean_projs)-1)*clean_projs.std()**2) / (len(jb_projs)+len(clean_projs)-2))\n",
    "        cohens_d = (jb_projs.mean() - clean_projs.mean()) / pooled_std\n",
    "        \n",
    "        print(f\"\\nJailbreak projections: mean={jb_projs.mean():.3f}, std={jb_projs.std():.3f}\")\n",
    "        print(f\"Clean projections: mean={clean_projs.mean():.3f}, std={clean_projs.std():.3f}\")\n",
    "        print(f\"\\nMann-Whitney U test (jailbreak < clean):\")\n",
    "        print(f\"  Statistic: {stat:.2f}\")\n",
    "        print(f\"  p-value: {p:.4f}\")\n",
    "        print(f\"  Effect size (Cohen's d): {cohens_d:.3f}\")\n",
    "        \n",
    "        if p < 0.05 and cohens_d < 0:\n",
    "            print(\"\\n*** HYPOTHESIS 1 SUPPORTED ***\")\n",
    "            print(\"Jailbreaks have significantly lower projections on the Assistant Axis.\")\n",
    "        else:\n",
    "            print(\"\\nHypothesis 1 NOT supported by this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Steering Experiments\n",
    "\n",
    "Test causal effects by steering activations toward/away from the Assistant Axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assistant_axis.steering import ActivationSteering\n",
    "\n",
    "if axis is not None:\n",
    "    # Test prompts\n",
    "    test_harmful = clean_harmful_prompts[:5]\n",
    "    \n",
    "    print(\"Steering Experiment: Can we prevent harmful outputs by steering toward Assistant?\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, prompt in enumerate(test_harmful):\n",
    "        print(f\"\\n--- Prompt {i+1}: {prompt[:80]}...\")\n",
    "        \n",
    "        # Baseline\n",
    "        baseline = pm.generate(prompt, max_new_tokens=100, temperature=0.0, do_sample=False)\n",
    "        print(f\"\\nBaseline: {baseline[:200]}...\")\n",
    "        \n",
    "        # Steered toward assistant (coefficient +2.0)\n",
    "        with ActivationSteering(\n",
    "            pm.model,\n",
    "            steering_vectors=[axis[TARGET_LAYER]],\n",
    "            coefficients=[2.0],\n",
    "            layer_indices=[TARGET_LAYER]\n",
    "        ):\n",
    "            steered = pm.generate(prompt, max_new_tokens=100, temperature=0.0, do_sample=False)\n",
    "        print(f\"\\nSteered (+2.0): {steered[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steering away from assistant (negative coefficient)\n",
    "if axis is not None:\n",
    "    print(\"\\nSteering Experiment: Can we induce harmful outputs by steering AWAY from Assistant?\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, prompt in enumerate(test_harmful[:3]):\n",
    "        print(f\"\\n--- Prompt {i+1}: {prompt[:80]}...\")\n",
    "        \n",
    "        # Baseline\n",
    "        baseline = pm.generate(prompt, max_new_tokens=100, temperature=0.0, do_sample=False)\n",
    "        print(f\"\\nBaseline: {baseline[:200]}...\")\n",
    "        \n",
    "        # Steered away from assistant (coefficient -2.0)\n",
    "        with ActivationSteering(\n",
    "            pm.model,\n",
    "            steering_vectors=[axis[TARGET_LAYER]],\n",
    "            coefficients=[-2.0],\n",
    "            layer_indices=[TARGET_LAYER]\n",
    "        ):\n",
    "            steered = pm.generate(prompt, max_new_tokens=100, temperature=0.0, do_sample=False)\n",
    "        print(f\"\\nSteered (-2.0): {steered[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "===============================================================================\n",
    "                         ANALYSIS CONCLUSIONS\n",
    "===============================================================================\n",
    "\n",
    "Based on the analysis performed in this notebook:\n",
    "\n",
    "1. ASSISTANT AXIS PROJECTIONS\n",
    "   - Measured projections of jailbreak vs clean prompts onto the Assistant Axis\n",
    "   - Hypothesis 1 (Anti-Assistant): [Result from statistical test]\n",
    "\n",
    "2. GLP META-NEURON ANALYSIS\n",
    "   - Trained H probe for harm detection\n",
    "   - [Add J and R results when available]\n",
    "\n",
    "3. STEERING EXPERIMENTS\n",
    "   - Tested causal effects of steering toward/away from Assistant\n",
    "   - [Summarize findings]\n",
    "\n",
    "4. OVERALL CONCLUSION\n",
    "   Based on the evidence:\n",
    "   - Hypothesis 1 (Anti-Assistant): [Supported/Not Supported]\n",
    "   - Hypothesis 2 (Harmful Persona): [Requires persona vector analysis]\n",
    "   - Hypothesis 3 (Both): [Assessment]\n",
    "   - Hypothesis 4 (Orthogonal): [Based on variance explained]\n",
    "\n",
    "NEXT STEPS:\n",
    "   - Compute full axis for Llama 3.1 8B using pipeline\n",
    "   - Generate more jailbreaks with nanoGCG\n",
    "   - Train J and R probes with response classification\n",
    "   - Analyze persona vector similarities\n",
    "\n",
    "===============================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "if 'pm' in dir():\n",
    "    pm.close()\n",
    "if 'glp' in dir():\n",
    "    del glp\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
